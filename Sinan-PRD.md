# 司南 (Sinan) 项目计划书

**AI 驱动的移动端自动化测试平台**

---

| 项目代号 | 司南 (Sinan) |
|---------|---------------------|
| 版本 | V1.0 |
| 日期 | 2025年1月 |
| 状态 | 内部技术规划 |

---

## 1. 项目概述

### 1.1 项目背景

当前移动端自动化测试面临以下核心痛点：

- 传统方案依赖控件 ID，跨平台（Android/鸿蒙）维护成本高
- UI 改版导致测试用例大面积失效，维护成本远超编写成本
- 鸿蒙生态缺乏成熟的自动化测试工具链
- 测试用例编写门槛高，需要专业测试工程师

本项目旨在利用多模态大模型（VLM）和 AI Agent 技术，构建一套以「视觉感知」替代「控件代码」的通用自动化测试平台，实现跨鸿蒙/安卓的统一测试能力。

### 1.2 项目目标

**核心目标（SMART 原则）：**

| 维度 | 目标描述 |
|-----|---------|
| Specific | 构建支持 Android 和鸿蒙 Next 双端的 AI 驱动自动化测试平台 |
| Measurable | MVP 阶段实现 80% 以上的常规 UI 操作自动化覆盖率 |
| Achievable | 基于现有开源项目（MAI-UI）进行二次开发，降低技术风险 |
| Relevant | 填补鸿蒙生态自动化测试工具空白，具备内部优势资源 |
| Time-bound | 6 个月内完成三阶段开发，MVP 在 2 个月内交付 |

### 1.3 项目范围

**范围内（In Scope）：**
- 桌面端执行器（Electron 应用）
- Android 和鸿蒙 Next 设备驱动层
- AI 探索式用例生成与执行引擎
- 云端用例管理与任务调度平台
- 测试报告生成与 AI 根因分析

**范围外（Out of Scope）：**
- iOS 平台支持（后续版本考虑）
- 性能测试、压力测试等非功能性测试
- 本地大模型推理（仅使用云端 API）

---

## 2. 技术方案

### 2.1 总体架构

采用「胖客户端 + 轻云端」的混合架构，核心 AI 推理和设备控制在本地执行，云端负责资产管理与协作。

```
┌─────────────────────────────────────────────────────────────┐
│                      云端 (Web Platform)                     │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────┐  │
│  │  Next.js    │  │ PostgreSQL  │  │  MinIO/S3 存储      │  │
│  │  管理后台   │  │  数据库     │  │  (截图/录屏)        │  │
│  └─────────────┘  └─────────────┘  └─────────────────────┘  │
└────────────────────────────┬────────────────────────────────┘
                             │ Sync JSON/Media
┌────────────────────────────┴────────────────────────────────┐
│                    桌面端 (Electron App)                     │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────┐  │
│  │  React UI   │  │  Python     │  │  MAI-UI             │  │
│  │  (投屏/控制)│  │  FastAPI    │  │  + Qwen-VL (云端)   │  │
│  └─────────────┘  └─────────────┘  └─────────────────────┘  │
└────────────────────────────┬────────────────────────────────┘
                             │ ADB / HDC
┌────────────────────────────┴────────────────────────────────┐
│                       设备层 (Device)                        │
│         ┌─────────────┐          ┌─────────────┐            │
│         │   Android   │          │  鸿蒙 Next  │            │
│         └─────────────┘          └─────────────┘            │
└─────────────────────────────────────────────────────────────┘
```

| 组件 | 职责 |
|-----|------|
| 桌面端 | 连接设备、运行 AI 模型、截图分析、执行操作、生成本地报告 |
| 云端 | 用例库管理、任务调度、历史数据分析、团队协作、权限管理 |
| 设备层 | Android（ADB）和鸿蒙（HDC/uitest）的统一抽象驱动 |

### 2.2 技术栈选型

**桌面端：**

| 模块 | 技术选型 | 选型理由 |
|-----|---------|---------|
| 外壳框架 | Electron + React | 跨平台，前端生态丰富，便于投屏展示 |
| 前端构建 | electron-vite | Electron 官方推荐的 Vite 构建方案，开箱即用 |
| 智能引擎 | Python 3.12+ / FastAPI | 本地 HTTP 服务，供 Electron 调用 |
| Python 工具链 | uv | Astral 出品，比 pip 快 10-100x，集成虚拟环境管理 |
| AI 核心 | MAI-UI | 阿里通义开源，成熟的移动端 Agent 方案 |
| 视觉模型 | Qwen-VL-Max (云端) | 精度高，无需本地 GPU |
| 打包工具 | PyInstaller | 无需用户安装 Python 环境 |

**脚手架与项目初始化：**

```bash
# Electron + React 项目（使用 electron-vite 官方模板）
npm create @quick-start/electron@latest sinan -- --template react

# 或克隆官方 React 模板
git clone https://github.com/electron-vite/electron-vite-react.git sinan

# Python 后端项目（使用 uv）
uv init sinan-core
cd sinan-core
uv add fastapi uvicorn websockets pillow
uv add --dev pytest ruff
```

**项目目录结构：**

```
sinan/
├── electron/                 # Electron 主进程
│   ├── main.ts
│   └── preload.ts
├── src/                      # React 渲染进程
│   ├── components/
│   │   ├── ChatPanel/        # AI 聊天框
│   │   ├── Canvas/           # React Flow 画布
│   │   └── Nodes/            # 用例节点、截图节点
│   ├── hooks/
│   ├── stores/               # Zustand 状态管理
│   └── App.tsx
├── core/                     # Python 后端（独立 uv 项目）
│   ├── src/
│   │   └── sinan_core/
│   │       ├── agents/       # AI Agent 模块
│   │       ├── drivers/      # 设备驱动层
│   │       ├── api/          # FastAPI 路由
│   │       └── main.py
│   ├── pyproject.toml
│   └── uv.lock
├── package.json
└── electron.vite.config.ts
```

**AI SDK 与交互层：**

采用「对话驱动测试」的设计理念，用户通过自然语言对话完成测试设计、用例生成、执行和分析的全流程。

| 模块 | 技术选型 | 选型理由 |
|-----|---------|---------|
| 前端 AI SDK | Vercel AI SDK | 与 Next.js 深度集成，流式渲染、聊天组件完善 |
| 后端 Agent | Python 自研 + MAI-UI | 灵活控制 Agent 逻辑，支持测试设计/决策/自愈 |
| 备选方案 | LangChain (Python) | 如需复杂 Agent 编排可引入，Tool/Memory 抽象成熟 |

**AI 能力分层：**

```
┌─────────────────────────────────────────────────────────┐
│                    对话交互层 (Vercel AI SDK)            │
│         聊天框 / 流式渲染 / Markdown / 拖拽画布          │
└────────────────────────────┬────────────────────────────┘
                             │
┌────────────────────────────┴────────────────────────────┐
│                    Agent 编排层 (Python)                 │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐ │
│  │ 测试设计  │  │ 用例生成  │  │ 执行决策  │  │ 自愈修复  │ │
│  │ Agent    │  │ Agent    │  │ Agent    │  │ Agent    │ │
│  └──────────┘  └──────────┘  └──────────┘  └──────────┘ │
└────────────────────────────┬────────────────────────────┘
                             │
┌────────────────────────────┴────────────────────────────┐
│                    执行层 (MAI-UI)                       │
│              UI 树解析 / 视觉识别 / 设备操作              │
└─────────────────────────────────────────────────────────┘
```

**UI 界面组件：**

| 模块 | 技术选型 | 说明 |
|-----|---------|------|
| 组件库 | Shadcn/UI + Tailwind | Vercel 生态标配，可定制性强 |
| 聊天组件 | Vercel AI SDK Chat | 内置流式渲染、消息历史管理 |
| Markdown 渲染 | react-markdown | 支持代码高亮、表格等 |
| 状态管理 | Zustand | 轻量简洁，适合中等复杂度项目 |
| 可视化画布 | React Flow | 用于展示用例执行链路、节点拖拽 |

**产品界面形态：**

```
┌─────────────────────────────────────────────────────────────────────┐
│                              司南 (Sinan)                             │
├─────────────────────────────────────┬───────────────────────────────┤
│                                     │                               │
│         可视化画布 (React Flow)      │       AI 聊天框               │
│         ┌─────┐      ┌─────┐        │                               │
│         │ TC1 │──────│ TC2 │        │   用户：帮我测试字体设置功能   │
│         │用例 │      │用例 │        │                               │
│         └──┬──┘      └──┬──┘        │   AI：好的，我来生成测试用例   │
│            │            │           │       ✅ 已生成 3 条用例       │
│         ┌──▼──┐      ┌──▼──┐        │                               │
│         │截图1│      │截图1│        │   用户：执行第一条             │
│         │     │      │     │        │                               │
│         └──┬──┘      └──┬──┘        │   AI：正在执行...             │
│            │            │           │       📸 步骤1 完成           │
│         ┌──▼──┐      ┌──▼──┐        │       📸 步骤2 完成           │
│         │截图2│      │截图2│        │                               │
│         └─────┘      └─────┘        │   [输入框]            [发送]  │
│                                     │                               │
└─────────────────────────────────────┴───────────────────────────────┘
```

**画布交互逻辑：**

1. **用例生成阶段**：AI 生成的用例以文本节点形式出现在画布上
2. **执行阶段**：每个操作步骤生成一个截图节点，自动连接到对应用例
3. **节点连通**：执行链路通过连线串联，形成完整的执行轨迹
4. **复盘模式**：点击任意节点可查看该步骤的详细信息（截图、操作、耗时）

**前后端通信：**

| 场景 | 方案 | 说明 |
|-----|------|------|
| AI 对话 | Vercel AI SDK (SSE) | 流式输出，SDK 内置支持 |
| 用例执行 | WebSocket | 双向实时通信，推送截图和状态更新 |
| 文件传输 | HTTP REST | 用例导入导出、截图下载 |

**WebSocket 消息类型：**

```typescript
// 客户端 → 服务端
{ type: "execute", payload: { caseId: "tc_001" } }
{ type: "stop", payload: { caseId: "tc_001" } }

// 服务端 → 客户端
{ type: "step_start", payload: { stepId: 1, action: "tap", target: "设置图标" } }
{ type: "step_done", payload: { stepId: 1, screenshot: "base64...", duration: 1200 } }
{ type: "case_done", payload: { caseId: "tc_001", result: "pass" } }
{ type: "error", payload: { message: "设备连接断开" } }
```

**投屏方案（后续版本）：**

MVP 阶段不做实时投屏，采用**执行时截图 + 画布节点展示**的方式呈现执行过程，更适合复盘场景。

| 平台 | 方案 | 说明 |
|-----|------|------|
| Android | scrcpy 集成 | 后续版本考虑，成熟方案 |
| 鸿蒙 Next | 待调研 | 后续版本考虑 |

**云端：**

| 模块 | 技术选型 | 选型理由 |
|-----|---------|---------|
| 全栈框架 | Next.js (App Router) | 前后端一体，部署简单 |
| 数据库 | PostgreSQL + Prisma | 关系型数据，ORM 类型安全 |
| 对象存储 | MinIO / S3 | 存储截图、录屏等媒体文件 |
| UI 组件 | Shadcn/UI + Tailwind | 与桌面端风格一致 |

**设备驱动：**

| 平台 | 通信方式 | UI 树获取 |
|-----|---------|----------|
| Android | ADB (pure-python-adb) | uiautomator dump |
| 鸿蒙 Next | HDC (subprocess 封装) | uitest dumpLayout |

### 2.3 分层决策策略

为优化成本和响应速度，采用分层控制策略，优先使用结构化数据（UI 树），仅在必要时调用视觉模型：

| 优先级 | 场景 | 实现方式 |
|-------|------|---------|
| P0 | 元素有明确 text/id/description | UI 树直接匹配，毫秒级，零成本 |
| P1 | 自然语言指令需映射到元素 | UI 树 + 轻量 LLM 做指令解析 |
| P2 | 自绘控件/图标/Canvas/WebView | 视觉模型兜底识别 |

**决策路由伪代码：**

```python
def decide_strategy(instruction, ui_tree):
    # 1. 先尝试从 UI 树找匹配
    candidates = fuzzy_match(instruction, ui_tree)
    
    if len(candidates) == 1:
        return "ui_tree", candidates[0]
    
    if len(candidates) > 1:
        # 多个候选，让 LLM 选
        return "llm_select", candidates
    
    # UI 树没找到，上视觉
    return "vision", None
```

---

## 3. 核心功能模块

### 3.1 对话驱动测试设计

采用「Web Testing」理念，用户通过对话完成测试全流程，而非传统的脚本编写。

**核心 Agent 职责：**

| Agent | 职责 | 阶段 |
|-------|------|------|
| 用例生成 Agent | 将测试需求转化为可执行用例 | **MVP** |
| 执行决策 Agent | 运行时选择最优执行策略（UI 树 / LLM / 视觉） | **MVP** |
| 测试设计 Agent | 根据需求文档/对话生成测试方案 | Phase 2 |
| 自愈修复 Agent | UI 变化后自动修正用例 | Phase 3 |

**对话交互示例：**

```
用户：帮我测试一下设置 App 里的字体大小功能

AI：好的，我来为「设置-字体大小」功能设计测试方案。
    
    📋 测试范围分析：
    1. 字体大小调节（小/中/大/超大）
    2. 调节后的即时预览效果
    3. 退出重进后设置是否保持
    
    是否需要我生成详细的测试用例？

用户：生成吧，重点测边界情况

AI：正在生成测试用例...
    
    ✅ 已生成 6 条用例：
    - TC001: 字体从默认调至最小
    - TC002: 字体从默认调至最大  
    - TC003: 连续调节（小→大→小）
    - TC004: 调节后退出 App 验证持久化
    - TC005: 调节后重启手机验证持久化
    - TC006: 不同 App 字体联动验证
    
    需要我现在执行哪些用例？
```

### 3.2 设备统一驱动层

设计抽象基类屏蔽 Android 和鸿蒙的底层差异，上层 AI 逻辑无需关心具体平台实现。

**核心接口：**

```python
class BaseDevice:
    def tap(self, x, y): pass
    def swipe(self, x1, y1, x2, y2): pass
    def screenshot(self) -> Image: pass
    def get_ui_tree(self) -> dict: pass
    def input_text(self, text): pass

class AndroidDevice(BaseDevice):
    # adb shell input tap x y
    # adb shell uiautomator dump

class HarmonyDevice(BaseDevice):
    # hdc shell uinput -T -d x y
    # hdc shell uitest dumpLayout
```

### 3.3 AI 探索式用例生成

用户输入自然语言指令，AI Agent 自动完成操作并生成可复用的测试用例。

**流程：**

1. 用户开启「录制/生成模式」，输入自然语言指令（如「把字体大小改为大号」）
2. Agent 获取 UI 树，尝试直接匹配目标元素
3. 匹配失败时，截图调用视觉模型识别并规划动作
4. 执行动作，记录每步的截图、操作类型、目标描述
5. 任务完成后，将操作序列序列化为 JSON 测试用例

**用例格式：**

```json
{
  "case_id": "tc_001",
  "case_name": "修改字体大小",
  "created_at": "2025-01-27T10:00:00Z",
  "steps": [
    {
      "step_id": 1,
      "action": "tap",
      "target_desc": "设置图标",
      "coordinates": [100, 200],
      "screenshot_ref": "step_001.png",
      "strategy_used": "ui_tree"
    },
    {
      "step_id": 2,
      "action": "tap",
      "target_desc": "显示与亮度",
      "coordinates": [100, 500],
      "screenshot_ref": "step_002.png",
      "strategy_used": "vision"
    }
  ]
}
```

### 3.4 自愈执行引擎

解决「UI 改版测试就挂」的核心痛点。执行用例时，不仅依赖坐标，还保留目标元素的语义描述。

**执行流程：**

1. 加载用例，读取每步的目标描述和参考坐标
2. 先用 UI 树查找目标元素，若匹配成功直接执行
3. 若 UI 树匹配失败，截图让视觉模型重新定位
4. 定位成功后执行操作，并标记「用例已自动修正」
5. 修正后的坐标可选择同步回用例库

### 3.5 云端智能复盘

测试失败后的自动化分析能力：

- **视觉 Diff**：对比基准截图与失败截图，高亮差异区域
- **AI 根因分析**：输入日志和截图，判断失败原因（加载慢/报错/遮挡等）
- **报告生成**：包含视频回放、归因分析的 HTML 报告

---

## 4. 项目计划

### 4.1 阶段划分

#### 第一阶段：MVP（用例生成 + 执行可视化）

| 项目 | 内容 |
|-----|------|
| 周期 | 8 周 |
| 目标 | 跑通「对话生成用例 → 执行 → 画布可视化」核心流程 |
| 交付物 | 桌面应用：AI 聊天框 + 可视化画布 + 设备执行 + 截图节点展示 |

**MVP 核心功能：**
- 对话式用例生成（自然语言 → JSON 用例）
- 用例执行（UI 树优先 + 视觉兜底）
- 画布可视化（用例节点 + 执行截图节点 + 连线）
- 支持 Android + 鸿蒙设备

#### 第二阶段：平台化 + 测试设计

| 项目 | 内容 |
|-----|------|
| 周期 | 8 周 |
| 目标 | 云端协作 + 测试设计 Agent |
| 交付物 | Web 管理后台 + 测试设计能力 |

**Phase 2 核心功能：**
- 用例云端同步与管理
- 测试设计 Agent（需求 → 测试方案 → 用例）
- 多机并发调度
- 执行结果汇总与历史记录

#### 第三阶段：智能化（自愈与分析）

| 项目 | 内容 |
|-----|------|
| 周期 | 8 周 |
| 目标 | 解决用例维护问题，增加智能复盘 |
| 交付物 | 自愈能力 + AI 归因分析 + 可视化报告 |

**Phase 3 核心功能：**
- UI 变动后的用例自动修复（自愈 Agent）
- 测试失败的 AI 自动归因
- 可视化测试报告（执行轨迹回放 + 分析）

### 4.2 里程碑节点

| 时间 | 里程碑 | 验收标准 |
|-----|-------|---------|
| W2 | 设备驱动层完成 | Android/鸿蒙设备可连接、截图、点击 |
| W4 | AI 核心集成 | 自然语言指令可驱动完成简单任务 |
| W6 | 分层决策实现 | UI 树优先匹配，视觉模型兜底 |
| W8 | **MVP 交付** | Electron 应用可用，内部演示通过 |
| W12 | 云端基础版 | 用例上传/下载/编辑功能可用 |
| W16 | **平台化完成** | 多机调度、结果汇总功能可用 |
| W20 | 自愈能力上线 | 用例自动修正成功率 > 70% |
| W24 | **全功能交付** | AI 归因分析、报告生成完整可用 |

### 4.3 MVP 任务拆解（第一阶段详细）

#### Week 1-2：项目搭建 + 设备驱动层

- [ ] 使用 electron-vite 创建 React 项目骨架
- [ ] 使用 uv 初始化 Python 后端项目
- [ ] 设计 `BaseDevice` 抽象接口
- [ ] 实现 `AndroidDevice`（ADB 封装）
- [ ] 实现 `HarmonyDevice`（HDC 封装）
- [ ] 实现 `uitest dumpLayout` 解析器
- [ ] 设备连接状态检测与重连机制
- [ ] 截图接口实现

#### Week 3-4：AI 核心集成

- [ ] 集成 MAI-UI 核心模块
- [ ] 对接 Qwen-VL-Max API
- [ ] 实现用例生成 Agent（自然语言 → JSON 用例）
- [ ] 实现执行决策 Agent（UI 树优先 → 视觉兜底）
- [ ] 操作历史记录

#### Week 5-6：前端框架搭建

- [ ] Next.js + Vercel AI SDK 项目初始化
- [ ] AI 聊天框组件（流式渲染、消息历史）
- [ ] React Flow 画布集成
- [ ] 用例节点组件（文本形态）
- [ ] 截图节点组件（图片 + 操作信息）
- [ ] 节点连线与布局算法

#### Week 7-8：端到端整合

- [ ] WebSocket 服务搭建（Python FastAPI + websockets）
- [ ] 前端 WebSocket 客户端封装
- [ ] 用例生成 → 画布展示流程
- [ ] 用例执行 → 实时截图节点更新（WebSocket 推送）
- [ ] 执行状态同步（进行中 / 成功 / 失败）
- [ ] 本地 JSON 用例导入导出
- [ ] 打包测试（Windows/macOS）

---

## 5. 资源计划

### 5.1 人员配置

| 角色 | 职责 | 人数/投入 |
|-----|------|----------|
| 项目负责人 | 整体规划、技术决策、进度把控 | 1 人（兼任开发） |
| Python 开发 | AI 引擎、设备驱动、核心逻辑 | 1 人 × 全程 |
| 前端开发 | Electron 应用、Web 管理后台 | 1 人 × 全程 |
| 测试/验证 | 功能验证、用例编写、反馈 | 1 人（阶段性） |

### 5.2 设备与环境

- 开发机：macOS/Windows（需支持 ADB 和 HDC）
- 测试设备：Android 手机 2 台、鸿蒙 Next 手机 2 台
- 云服务：阿里云 DashScope（Qwen-VL API）、PostgreSQL 数据库、MinIO 存储

### 5.3 预算估算

| 项目 | 预估费用/月 | 备注 |
|-----|-----------|------|
| Qwen-VL API | ¥500-2000 | 视调用量，可通过缓存优化 |
| 云服务器 | ¥200-500 | 轻量应用服务器即可 |
| 对象存储 | ¥50-200 | 按存储量计费 |
| **合计** | **¥750-2700/月** | MVP 阶段预计偏低 |

---

## 6. 风险管理

| 风险点 | 等级 | 应对策略 |
|-------|-----|---------|
| API 调用成本过高 | 中 | 引入缓存层，相同页面 Hash 复用识别结果；简单操作用 UI 树匹配 |
| AI 推理延迟影响体验 | 中 | 操作间隙显示思考动画；高频简单操作用本地 OCR 替代 |
| 鸿蒙系统更新导致 HDC 变化 | 低 | 驱动层封装隔离，HDC 变更只影响 Driver 类；内部资源可快速响应 |
| Electron 打包体积过大 | 中 | Python 环境与模型分开下载；首次启动时拉取 |
| 视觉模型识别准确率不足 | 中 | 分层策略：UI 树优先；积累 bad case 做 prompt 优化 |
| Python 长时间运行内存泄漏 | 中 | 定期重启 Python 进程；图像对象及时释放 |

---

## 7. 质量保证

### 7.1 验收标准

- **MVP**：完成 10 个以上标准测试场景的自动化执行
- **平台化**：支持 3 台以上设备并发执行
- **智能化**：用例自愈成功率 > 70%，AI 归因准确率 > 80%

### 7.2 测试策略

- **单元测试**：核心模块（驱动层、决策路由）覆盖率 > 80%
- **集成测试**：端到端场景验证，覆盖主流 App（设置、文件管理、浏览器）
- **回归测试**：每次迭代前跑通核心用例集

### 7.3 评审机制

- 每周技术评审：review 代码实现，讨论技术难点
- 里程碑评审：交付物验收，确认是否进入下一阶段

---

## 8. 附录

### 8.1 术语表

| 术语 | 定义 |
|-----|------|
| VLM | Vision-Language Model，视觉语言模型，能同时处理图像和文本 |
| MAI-UI | 阿里通义开源的移动端 AI Agent 框架，基于视觉感知操作手机 |
| ADB | Android Debug Bridge，Android 设备调试工具 |
| HDC | HarmonyOS Device Connector，鸿蒙设备调试工具 |
| UI 树 | 界面控件的层级结构数据，包含元素类型、位置、文本等属性 |
| 自愈 | Self-Healing，测试用例在 UI 变化后自动修正定位的能力 |

### 8.2 参考资料

- MAI-UI：https://tongyi-mai.github.io/MAI-UI-blog/
- android-action-kernel (Action-State-Labs)：https://github.com/Action-State-Labs/android-action-kernel
- Qwen-VL：https://github.com/QwenLM/Qwen-VL
- 鸿蒙 uitest 文档：HarmonyOS Developer 官方文档

### 8.3 待定事项（TODO）

- [ ] 鸿蒙 `uitest dumpLayout` 输出格式分析与解析器设计
- [ ] 用例 JSON 版本管理策略（自愈修正后的用例如何与原始用例关联）
- [ ] Electron 与 Python 进程间通信的具体实现方案
- [ ] 端口冲突处理策略

---

*文档版本：V1.0 | 最后更新：2025年1月*
